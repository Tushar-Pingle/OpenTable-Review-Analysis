{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is written according to the layout of UI and HTML layout of the page which dispalys the information for individual restaurants on OpenTable\n",
    "## There is a if statement in place that only allows the first 300 reviews to be scrapped, however if the 300th review is on a new page, it will scrap the full page and therefore you can have more that 300 reviews in some conditions\n",
    "## Two additional parameters \"Cusine\" and \"Location\" arr also being scrapped that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.page_load_strategy = 'eager'  # Can be 'eager' or 'none'\n",
    "\n",
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get('https://www.opentable.ca/the-lobby-pinnacle-hotel-at-the-pier?corrid=096ba9c2-17b5-4fe5-a52a-ef84d26deca8&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&p=2&sd=2024-02-01T19%3A00%3A00')\n",
    "\n",
    "Name = []\n",
    "Date = []\n",
    "Over_Rating = []\n",
    "Food_Rating = []\n",
    "Service_Rating = []\n",
    "Ambience_Rating = []\n",
    "Review = []\n",
    "Cusine = []\n",
    "Location = []\n",
    "\n",
    "review_counter = 0\n",
    "\n",
    "\n",
    "try:\n",
    "    page_count = 0\n",
    "    while True:  # Continue until the \"Next\" button can't be found\n",
    "        # Increment page counter\n",
    "        page_count += 1\n",
    "        print(f\"Page {page_count}\")\n",
    "        \n",
    "        # Wait for the reviews section to load\n",
    "        reviews_section = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"restProfileReviewsContent\"]'))\n",
    "        )\n",
    "        \n",
    "        # Find all individual review containers within the reviews section\n",
    "        reviews = reviews_section.find_elements(By.CLASS_NAME, 'afkKaa-4T28-') \n",
    "        \n",
    "        for review in reviews:\n",
    "            if review_counter >= 300:  # Stop after scraping 300 reviews\n",
    "                print(\"Reached 300 reviews.\")\n",
    "                break\n",
    "        \n",
    "        for review in reviews:\n",
    "            # Extract the details from each review\n",
    "            name = review.find_element(By.CSS_SELECTOR, 'section > p._1p30XHjz2rI-.C7Tp-bANpE4-').text\n",
    "            date = review.find_element(By.CSS_SELECTOR, 'div > div.yuQYBV659bs-.C7Tp-bANpE4- > p').text\n",
    "            overall_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(1) > span').text\n",
    "            food_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(2) > span').text\n",
    "            service_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(3) > span').text\n",
    "            ambience_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(4) > span').text\n",
    "            review_text = review.find_element(By.CSS_SELECTOR, 'div > div._6rFG6U7PA6M- > span:nth-child(1)').text\n",
    "            cusine = review.find_element(By.XPATH, '//*[@id=\"mainContent\"]/div/div[2]/div[1]/section[2]/div[5]/section[1]/div/div/div/div/ul[1]/li[3]/div/div/div').text\n",
    "            location = review.find_element(By.XPATH, '//*[@id=\"mainContent\"]/div/div[2]/div[1]/section[2]/div[5]/section[1]/div/div/div/div/ul[2]/li[1]/div/div/div/a').text\n",
    "            \n",
    "            \n",
    "            Name.append(name)\n",
    "            Date.append(date)\n",
    "            Over_Rating.append(overall_rating)\n",
    "            Food_Rating.append(food_rating)\n",
    "            Service_Rating.append(service_rating)\n",
    "            Ambience_Rating.append(ambience_rating)\n",
    "            Review.append(review_text)\n",
    "            Cusine.append(cusine)\n",
    "            Location.append(location)\n",
    "            \n",
    "            # Print out the extracted information\n",
    "            #print(\"Name: \" + name)\n",
    "            #print(\"Date: \" + date)\n",
    "            #print(\"Overall Rating: \" + overall_rating)\n",
    "            #print(\"Food Rating: \" + food_rating)\n",
    "            #print(\"Service Rating: \" + service_rating)\n",
    "            #print(\"Ambience Rating: \" + ambience_rating)\n",
    "            #print(\"Review: \" + review_text + \"\\n\")\n",
    "            review_counter += 1\n",
    "\n",
    "        if review_counter >= 300:\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Wait for the \"Next\" button to be clickable\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        try:\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"reviews\"]/section/footer/div/div[2]/a')))\n",
    "            next_button.click()\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            # \"Next\" button is not present or not clickable, exit the loop\n",
    "            print(\"Reached the last page or the next button is not clickable.\")\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            # The reference to the button is stale, re-find the button\n",
    "            continue\n",
    "\n",
    "        # Wait for a specific element that indicates the new page has loaded\n",
    "        # Replace 'unique_element_xpath_on_new_page' with the actual XPATH\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"reviews\"]/section/footer/div/div[2]/a'))\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions\n",
    "    print(\"An error occurred:\", e)\n",
    "finally:\n",
    "    # Close the browser when done\n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "    df= pd.DataFrame(\n",
    "    {'Name': Name,\n",
    "     'Date': Date,\n",
    "     'Cusine' : Cusine,\n",
    "     'Overall_rating': Over_Rating,\n",
    "     'Food_rating': Food_Rating,\n",
    "     'Service_rating': Service_Rating,\n",
    "     'Ambience_Rating': Ambience_Rating,\n",
    "     'Review': Review,\n",
    "     'Location' : Location})\n",
    "\n",
    "# Add a new column with the same value for all rows\n",
    "df['Restaurant'] = 'The Lobby'\n",
    "\n",
    "\n",
    "df.to_csv(\"C:/Users/12367/Documents/Python Scripts/Open Table Review.csv\", index=False, mode='a', header= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is written according to the layout of UI and HTML layout of the page which dispalys the information for individual restaurants on OpenTable\n",
    "## The following code will execute till all the reviews are scrapped, depending on the computational power, I will suggest to move the statements for adding the data to a dataframe and saving it to a .csv file to be mode to a new block of code and to be executed seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "Page 2\n",
      "Page 3\n",
      "Page 4\n",
      "An error occurred: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6E7525E42+3538674]\n",
      "\t(No symbol) [0x00007FF6E7144C02]\n",
      "\t(No symbol) [0x00007FF6E6FF5AEB]\n",
      "\t(No symbol) [0x00007FF6E703BF4E]\n",
      "\t(No symbol) [0x00007FF6E703C0CC]\n",
      "\t(No symbol) [0x00007FF6E707E477]\n",
      "\t(No symbol) [0x00007FF6E705F0EF]\n",
      "\t(No symbol) [0x00007FF6E707BDE3]\n",
      "\t(No symbol) [0x00007FF6E705EE53]\n",
      "\t(No symbol) [0x00007FF6E702F514]\n",
      "\t(No symbol) [0x00007FF6E7030631]\n",
      "\tGetHandleVerifier [0x00007FF6E7556CAD+3738973]\n",
      "\tGetHandleVerifier [0x00007FF6E75AC506+4089270]\n",
      "\tGetHandleVerifier [0x00007FF6E75A4823+4057299]\n",
      "\tGetHandleVerifier [0x00007FF6E7275C49+720121]\n",
      "\t(No symbol) [0x00007FF6E715126F]\n",
      "\t(No symbol) [0x00007FF6E714C304]\n",
      "\t(No symbol) [0x00007FF6E714C432]\n",
      "\t(No symbol) [0x00007FF6E713BD04]\n",
      "\tBaseThreadInitThunk [0x00007FF8DAB07344+20]\n",
      "\tRtlUserThreadStart [0x00007FF8DBB626B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.page_load_strategy = 'eager'  # Can be 'eager' or 'none'\n",
    "\n",
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get('https://www.opentable.ca/homer-street-cafe-and-bar?corrid=f258c8b1-5951-4a15-9b29-ffa9a838ec23&avt=eyJ2IjoyLCJtIjoxLCJwIjowLCJzIjowLCJuIjowfQ&p=2&sd=2024-02-01T19%3A00%3A00')\n",
    "\n",
    "Name = []\n",
    "Date = []\n",
    "Over_Rating = []\n",
    "Food_Rating = []\n",
    "Service_Rating = []\n",
    "Ambience_Rating = []\n",
    "Review = []\n",
    "\n",
    "\n",
    "try:\n",
    "    page_count = 0\n",
    "    while True:  # Continue until the \"Next\" button can't be found\n",
    "        # Increment page counter\n",
    "        page_count += 1\n",
    "        print(f\"Page {page_count}\")\n",
    "        \n",
    "        # Wait for the reviews section to load\n",
    "        reviews_section = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"restProfileReviewsContent\"]'))\n",
    "        )\n",
    "        \n",
    "        # Find all individual review containers within the reviews section\n",
    "        reviews = reviews_section.find_elements(By.CLASS_NAME, 'afkKaa-4T28-') \n",
    "        \n",
    "        for review in reviews:\n",
    "            # Extract the details from each review\n",
    "            name = review.find_element(By.CSS_SELECTOR, 'section > p._1p30XHjz2rI-.C7Tp-bANpE4-').text\n",
    "            date = review.find_element(By.CSS_SELECTOR, 'div > div.yuQYBV659bs-.C7Tp-bANpE4- > p').text\n",
    "            overall_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(1) > span').text\n",
    "            food_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(2) > span').text\n",
    "            service_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(3) > span').text\n",
    "            ambience_rating = review.find_element(By.CSS_SELECTOR, 'div > ol > li:nth-child(4) > span').text\n",
    "            review_text = review.find_element(By.CSS_SELECTOR, 'div > div._6rFG6U7PA6M- > span:nth-child(1)').text\n",
    "            \n",
    "            Name.append(name)\n",
    "            Date.append(date)\n",
    "            Over_Rating.append(overall_rating)\n",
    "            Food_Rating.append(food_rating)\n",
    "            Service_Rating.append(service_rating)\n",
    "            Ambience_Rating.append(ambience_rating)\n",
    "            Review.append(review_text)\n",
    "            \n",
    "            # Print out the extracted information\n",
    "            #print(\"Name: \" + name)\n",
    "            #print(\"Date: \" + date)\n",
    "            #print(\"Overall Rating: \" + overall_rating)\n",
    "            #print(\"Food Rating: \" + food_rating)\n",
    "            #print(\"Service Rating: \" + service_rating)\n",
    "            #print(\"Ambience Rating: \" + ambience_rating)\n",
    "            #print(\"Review: \" + review_text + \"\\n\")\n",
    "        \n",
    "        # Wait for the \"Next\" button to be clickable\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        try:\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"reviews\"]/section/footer/div/div[2]/a')))\n",
    "            next_button.click()\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            # \"Next\" button is not present or not clickable, exit the loop\n",
    "            print(\"Reached the last page or the next button is not clickable.\")\n",
    "            break\n",
    "        except StaleElementReferenceException:\n",
    "            # The reference to the button is stale, re-find the button\n",
    "            continue\n",
    "\n",
    "        # Wait for a specific element that indicates the new page has loaded\n",
    "        # Replace 'unique_element_xpath_on_new_page' with the actual XPATH\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"reviews\"]/section/footer/div/div[2]/a'))\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions\n",
    "    print(\"An error occurred:\", e)\n",
    "finally:\n",
    "    # Close the browser when done\n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "    df= pd.DataFrame(\n",
    "    {'Name': Name,\n",
    "     'Date': Date,\n",
    "     'Overall_rating': Over_Rating,\n",
    "     'Food_rating': Food_Rating,\n",
    "     'Service_rating': Service_Rating,\n",
    "     'Ambience_Rating': Ambience_Rating,\n",
    "     'Review': Review})\n",
    "\n",
    "# Add a new column with the same value for all rows\n",
    "df['Restaurant'] = 'Homer Street Cafe & Bar'\n",
    "\n",
    "\n",
    "df.to_csv(\"C:/Users/12367/Documents/Python Scripts/Miku Restaurant Open Table Review.csv\", mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
